{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":62857,"databundleVersionId":6886092,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\ntrain_data = pd.read_csv(\"/kaggle/input/ys19-2023-assignment-1/train_set.csv\")\nvalid_data = pd.read_csv(\"/kaggle/input/ys19-2023-assignment-1/valid_set.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/ys19-2023-assignment-1/test_set.csv\")\n\nprint(train_data)\n\ntrain_data.describe()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T17:32:29.422626Z","iopub.execute_input":"2023-11-23T17:32:29.423168Z","iopub.status.idle":"2023-11-23T17:32:30.542534Z","shell.execute_reply.started":"2023-11-23T17:32:29.423127Z","shell.execute_reply":"2023-11-23T17:32:30.541190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data['Party'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T17:32:30.544900Z","iopub.execute_input":"2023-11-23T17:32:30.545343Z","iopub.status.idle":"2023-11-23T17:32:30.565403Z","shell.execute_reply.started":"2023-11-23T17:32:30.545292Z","shell.execute_reply":"2023-11-23T17:32:30.564351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Cleaning, tokenization and lowercasing","metadata":{}},{"cell_type":"code","source":"import re\nimport unicodedata\nfrom nltk.tokenize import word_tokenize\n\ndef strip_accents(text):\n   return ''.join(c for c in unicodedata.normalize('NFD', text)\n                  if unicodedata.category(c) != 'Mn')\n\n# text cleaning and tokenization\ndef preprocess_text(text):\n    # remove links and tags\n    text = re.sub(r\"http\\S+|www\\S+|@[^\\s]+\", ' ', text)\n    \n    # remove acute accents from Greek vowels\n    text = strip_accents(text)\n    \n    # remove special characters\n    text = re.sub(r\"[^A-Za-z0-9Α-Ωα-ω]+\", ' ', text)\n    \n    # tokenize the text\n    tokens = word_tokenize(text)\n    \n    # lowercasing\n    tokens = [token.lower() for token in tokens]\n    \n    return ' '.join(tokens)\n\ntrain_data['Processed_Text'] = train_data['Text'].apply(preprocess_text)\nvalid_data['Processed_Text'] = valid_data['Text'].apply(preprocess_text)\ntest_data['Processed_Text'] = test_data['Text'].apply(preprocess_text)\nprint(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T17:32:30.567070Z","iopub.execute_input":"2023-11-23T17:32:30.567929Z","iopub.status.idle":"2023-11-23T17:32:53.998496Z","shell.execute_reply.started":"2023-11-23T17:32:30.567864Z","shell.execute_reply":"2023-11-23T17:32:53.997165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lemmatization","metadata":{}},{"cell_type":"code","source":"!python -m spacy download el_core_news_sm","metadata":{"execution":{"iopub.status.busy":"2023-11-23T17:32:54.001515Z","iopub.execute_input":"2023-11-23T17:32:54.001878Z","iopub.status.idle":"2023-11-23T17:33:28.554874Z","shell.execute_reply.started":"2023-11-23T17:32:54.001846Z","shell.execute_reply":"2023-11-23T17:33:28.553405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy\n\n# model for lemmatizing Greek text\nnlp = spacy.load(\"el_core_news_sm\")  # * try el_core_news_md, el_core_news_lg\n\n# apply lemmatization\ndef lemmatize_greek_text(text):\n    doc = nlp(text)\n    lemmatized_tokens = [token.lemma_ for token in doc]\n    return ' '.join(lemmatized_tokens)\n\ntrain_data['Processed_Text'] = train_data['Processed_Text'].apply(lemmatize_greek_text)\nvalid_data['Processed_Text'] = valid_data['Processed_Text'].apply(lemmatize_greek_text)\ntest_data['Processed_Text'] = test_data['Processed_Text'].apply(lemmatize_greek_text)\nprint(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T17:33:28.557144Z","iopub.execute_input":"2023-11-23T17:33:28.557530Z","iopub.status.idle":"2023-11-23T17:42:18.871651Z","shell.execute_reply.started":"2023-11-23T17:33:28.557495Z","shell.execute_reply":"2023-11-23T17:42:18.870181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\n# generate word clouds graph\ndef generate_word_cloud(text, title):\n    wordcloud = WordCloud(background_color='white').generate(text)\n\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.title(title)\n    plt.show()\n\ngenerate_word_cloud(' '.join(train_data['Processed_Text']), 'Word Cloud - Training Data')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T18:40:39.244461Z","iopub.execute_input":"2023-11-23T18:40:39.244926Z","iopub.status.idle":"2023-11-23T18:40:47.803986Z","shell.execute_reply.started":"2023-11-23T18:40:39.244875Z","shell.execute_reply":"2023-11-23T18:40:47.802795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Vectorization","metadata":{}},{"cell_type":"markdown","source":"Vectorization using TF-IDF","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer()\n\n# fit and transform in the training data\ntrain_tfidf = tfidf.fit_transform(train_data['Processed_Text'])\n\n# transform for the validation and test data\nvalid_tfidf = tfidf.transform(valid_data['Processed_Text'])\ntest_tfidf = tfidf.transform(test_data['Processed_Text'])","metadata":{"execution":{"iopub.status.busy":"2023-11-23T17:42:28.615584Z","iopub.execute_input":"2023-11-23T17:42:28.616061Z","iopub.status.idle":"2023-11-23T17:42:30.556374Z","shell.execute_reply.started":"2023-11-23T17:42:28.616017Z","shell.execute_reply":"2023-11-23T17:42:30.554400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic regression model implementation ","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\nlogistic_regression = LogisticRegression(max_iter=1000)\n\n# fitting to the training data\nlogistic_regression.fit(train_tfidf, train_data['Sentiment'])\n\n# prediction\nvalid_predicted = logistic_regression.predict(valid_tfidf)\n\n# evaluation\naccuracy = accuracy_score(valid_data['Sentiment'], valid_predicted)\nreport = classification_report(valid_data['Sentiment'], valid_predicted)\n\nprint(f\"Accuracy on the validation set: {accuracy:.2f}\")\nprint(\"\\nClassification Report:\\n\", report)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T17:42:30.558540Z","iopub.execute_input":"2023-11-23T17:42:30.559365Z","iopub.status.idle":"2023-11-23T17:42:52.836760Z","shell.execute_reply.started":"2023-11-23T17:42:30.559314Z","shell.execute_reply":"2023-11-23T17:42:52.835836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Optimizing the hyperparameters","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n# the hyperparameters that will be tested\nparam_grid = {\n    'max_iter': [1000, 2000, 5000],\n    'C': [0.001, 0.01, 0.1, 1, 10],\n    'solver': ['newton-cg', 'lbfgs', 'liblinear','sag','saga'],\n#     'penalty': ['l1', 'l2', 'elasticnet'],\n}\n\ngrid_search = GridSearchCV(logistic_regression, param_grid, cv=5, scoring='accuracy')\n\ngrid_search.fit(train_tfidf, train_data['Sentiment'])\n\nbest_params = grid_search.best_params_\nbest_score = grid_search.best_score_\n\nprint(\"Best Parameters:\", best_params)\nprint(\"Best Accuracy Score:\", best_score)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T17:42:52.838190Z","iopub.execute_input":"2023-11-23T17:42:52.838687Z","iopub.status.idle":"2023-11-23T18:12:37.215144Z","shell.execute_reply.started":"2023-11-23T17:42:52.838657Z","shell.execute_reply":"2023-11-23T18:12:37.213942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n# import matplotlib.pyplot as plt\n\nlist_f1 = []\nlist_f1_train = []\nlist_sample_size = []\n\nfor times in range(10):\n    # training\n    X, X_unused, y, y_unused = train_test_split(train_tfidf, train_data['Sentiment'], test_size=1 - (times * 0.1 + 0.001))\n\n    logistic_regression = LogisticRegression(max_iter=5000, C=0.01, solver='saga')\n    logistic_regression.fit(X, np.ravel(y))\n\n    results_train = logistic_regression.predict(X)\n\n    # validation\n    results = logistic_regression.predict(valid_tfidf)\n\n    # score\n    f1_train = f1_score(y, results_train, average='weighted')\n    print(\"F1 Score Train: \" + str(f1_train))\n\n    f1 = f1_score(valid_data['Sentiment'], results, average='weighted')\n    print(\"F1 Score Validation: \" + str(f1))\n\n    list_f1.append(f1)\n    list_f1_train.append(f1_train)\n    list_sample_size.append((times * 0.1 + 0.1))\n\nplt.plot(list_sample_size, list_f1)\nplt.plot(list_sample_size, list_f1_train)\n\nplt.ylim(ymin=0)\nplt.legend([\"Validation\", \"Training\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T18:12:37.219276Z","iopub.execute_input":"2023-11-23T18:12:37.219933Z","iopub.status.idle":"2023-11-23T18:12:46.923782Z","shell.execute_reply.started":"2023-11-23T18:12:37.219873Z","shell.execute_reply":"2023-11-23T18:12:46.922600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Retrain the model with the best parameters to re evaluate","metadata":{}},{"cell_type":"code","source":"logistic_regression = LogisticRegression(max_iter=5000, C=0.01, solver='saga')\n\n# fitting to the training data\nlogistic_regression.fit(train_tfidf, train_data['Sentiment'])\n\n# prediction\nvalid_predicted = logistic_regression.predict(valid_tfidf)\n\n# evaluation\naccuracy = accuracy_score(valid_data['Sentiment'], valid_predicted)\nreport = classification_report(valid_data['Sentiment'], valid_predicted)\n\nprint(f\"Accuracy on the validation set: {accuracy:.2f}\")\nprint(\"\\nClassification Report:\\n\", report)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T18:18:56.051622Z","iopub.execute_input":"2023-11-23T18:18:56.052112Z","iopub.status.idle":"2023-11-23T18:18:57.561125Z","shell.execute_reply.started":"2023-11-23T18:18:56.052068Z","shell.execute_reply":"2023-11-23T18:18:57.559967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Output prediction","metadata":{}},{"cell_type":"code","source":"test_prediction = logistic_regression.predict(test_tfidf)\nsubmission = pd.DataFrame({'Id': test_data['New_ID'], 'Predicted': test_prediction})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T18:24:21.709085Z","iopub.execute_input":"2023-11-23T18:24:21.709517Z","iopub.status.idle":"2023-11-23T18:24:21.752158Z","shell.execute_reply.started":"2023-11-23T18:24:21.709483Z","shell.execute_reply":"2023-11-23T18:24:21.750816Z"},"trusted":true},"execution_count":null,"outputs":[]}]}